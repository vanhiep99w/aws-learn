# Amazon EBS (Elastic Block Store)

## EBS l√† g√¨?

Amazon Elastic Block Store (EBS) l√† d·ªãch v·ª• **block storage** c√≥ hi·ªáu su·∫•t cao, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ s·ª≠ d·ª•ng v·ªõi Amazon EC2. EBS cho ph√©p b·∫°n t·∫°o c√°c storage volumes v√† attach v√†o EC2 instances.

**ƒê·∫∑c ƒëi·ªÉm ch√≠nh:**
- Ho·∫°t ƒë·ªông nh∆∞ ·ªï c·ª©ng ·∫£o (virtual hard drive) cho EC2
- D·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u tr·ªØ ƒë·ªôc l·∫≠p v·ªõi v√≤ng ƒë·ªùi c·ªßa EC2 instance
- C√≥ th·ªÉ detach t·ª´ instance n√†y v√† attach v√†o instance kh√°c (c√πng Availability Zone)
- T·ª± ƒë·ªông replicate trong m·ªôt Availability Zone ƒë·ªÉ ƒë·∫£m b·∫£o durability

> üìñ **Ngu·ªìn:** [What is Amazon EBS?](https://docs.aws.amazon.com/ebs/latest/userguide/what-is-ebs.html)

---

## V√≠ d·ª• th·ª±c t·∫ø: EBS d√πng ƒë·ªÉ l√†m g√¨?

### Scenario 1: Web Server v·ªõi Database

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           EC2 Instance                  ‚îÇ
‚îÇ         (Web Application)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  EBS Volume 1 (gp3, 8GB)               ‚îÇ  ‚Üê Root volume (OS: Ubuntu)
‚îÇ  /dev/xvda                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  EBS Volume 2 (gp3, 100GB)             ‚îÇ  ‚Üê Data volume (MySQL data)
‚îÇ  /dev/xvdb ‚Üí mount /data                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**L·ª£i √≠ch:**
- Stop EC2 ‚Üí d·ªØ li·ªáu MySQL v·∫´n c√≤n
- Terminate EC2 ‚Üí data volume v·∫´n gi·ªØ ƒë∆∞·ª£c (n·∫øu set `DeleteOnTermination=false`)
- T·∫°o snapshot ‚Üí backup database tr∆∞·ªõc khi upgrade

### Scenario 2: Disaster Recovery

```
Ng√†y 1:  Volume (100GB data) ‚Üí Snapshot A
Ng√†y 7:  Volume th√™m 5GB    ‚Üí Snapshot B (ch·ªâ backup 5GB m·ªõi)
Ng√†y 14: Oops! X√≥a nh·∫ßm data

Recovery: Snapshot B ‚Üí T·∫°o Volume m·ªõi ‚Üí Attach v√†o EC2 ‚Üí Data tr·ªü l·∫°i!
```

---

## Root Volume vs Data Volume

### Root Volume l√† g√¨?

Khi launch EC2, AWS t·ª± ƒë·ªông t·∫°o **Root Volume** t·ª´ AMI. ƒê√¢y l√† EBS volume ch·ª©a **to√†n b·ªô h·ªá ƒëi·ªÅu h√†nh**:

```
Root Volume (/dev/xvda)
‚îÇ
‚îú‚îÄ‚îÄ /boot          ‚Üí Kernel, bootloader (GRUB)
‚îú‚îÄ‚îÄ /etc           ‚Üí Config files (nginx.conf, ssh config...)
‚îú‚îÄ‚îÄ /home          ‚Üí User files, SSH keys
‚îú‚îÄ‚îÄ /var           ‚Üí Logs, app data, databases (n·∫øu c√†i ·ªü ƒë√¢y)
‚îú‚îÄ‚îÄ /usr           ‚Üí Installed programs (nginx, python, nodejs...)
‚îú‚îÄ‚îÄ /opt           ‚Üí Custom software
‚îî‚îÄ‚îÄ /root          ‚Üí Root user's home
```

**V√≠ d·ª•:** B·∫°n launch EC2 Ubuntu, c√†i ƒë·∫∑t nginx, nodejs, mysql ‚Üí t·∫•t c·∫£ ƒë·ªÅu n·∫±m trong root volume.

### T·∫°o EBS Volume m·ªõi

Khi b·∫°n t·∫°o EBS volume m·ªõi (kh√¥ng t·ª´ snapshot) ‚Üí **·ªï c·ª©ng tr·ªëng** v·ªõi size b·∫°n ch·ªçn.

```
T·∫°o EBS Volume m·ªõi
‚îú‚îÄ‚îÄ Size: 100 GB
‚îú‚îÄ‚îÄ Type: gp3
‚îî‚îÄ‚îÄ Tr·∫°ng th√°i: TR·ªêNG (ch∆∞a c√≥ g√¨, ch∆∞a c√≥ filesystem)
```

### 2 c√°ch t·∫°o EBS Volume

| C√°ch t·∫°o | K·∫øt qu·∫£ |
|----------|---------|
| **T·∫°o m·ªõi (blank)** | ·ªî tr·ªëng, c·∫ßn format |
| **T·∫°o t·ª´ Snapshot** | C√≥ s·∫µn data v√† filesystem |

### So s√°nh Root Volume vs Data Volume

| ƒê·∫∑c ƒëi·ªÉm | Root Volume | Data Volume |
|----------|-------------|-------------|
| T·∫°o b·ªüi | AWS (khi launch EC2) | B·∫°n (t·ª± t·∫°o) |
| N·ªôi dung ban ƒë·∫ßu | OS t·ª´ AMI | Tr·ªëng ho·∫∑c t·ª´ snapshot |
| Mount point | `/` | B·∫°n ch·ªçn (vd: `/data`) |
| DeleteOnTermination m·∫∑c ƒë·ªãnh | `true` (b·ªã x√≥a) | `false` (gi·ªØ l·∫°i) |

### Stop vs Terminate EC2

| H√†nh ƒë·ªông | Root Volume | Data Volume |
|-----------|-------------|-------------|
| **Stop** | ‚úÖ Gi·ªØ nguy√™n | ‚úÖ Gi·ªØ nguy√™n |
| **Terminate** | ‚ùå M·∫∑c ƒë·ªãnh b·ªã X√ìA | ‚úÖ M·∫∑c ƒë·ªãnh gi·ªØ l·∫°i |

> ‚ö†Ô∏è N·∫øu mu·ªën gi·ªØ root volume sau terminate ‚Üí set `DeleteOnTermination=false`

### Best Practice: T√°ch data ra volume ri√™ng

```
EC2 Instance
‚îú‚îÄ‚îÄ /dev/xvda (Root, 8GB)     ‚Üí Ch·ªâ OS + apps
‚îî‚îÄ‚îÄ /dev/xvdb (Data, 100GB)   ‚Üí mount /data
    ‚îú‚îÄ‚îÄ /data/mysql
    ‚îú‚îÄ‚îÄ /data/uploads
    ‚îî‚îÄ‚îÄ /data/logs
```

### T·∫°i sao kh√¥ng d√πng root volume cho t·∫•t c·∫£ + snapshot?

**C√¢u h·ªèi:** "Ch·ªâ c·∫ßn root volume r·ªìi snapshot l√† ƒë∆∞·ª£c, sao ph·∫£i t√°ch data volume?"

**Tr·∫£ l·ªùi:** C√≥ th·ªÉ, nh∆∞ng c√≥ nhi·ªÅu v·∫•n ƒë·ªÅ:

#### 1. R·ªßi ro DeleteOnTermination

```
Root Volume: DeleteOnTermination = true (m·∫∑c ƒë·ªãnh)
             ‚Üí Terminate EC2 = M·∫§T NGAY, kh√¥ng k·ªãp snapshot

Data Volume: DeleteOnTermination = false (m·∫∑c ƒë·ªãnh)
             ‚Üí Terminate EC2 = Data v·∫´n c√≤n
```

#### 2. Snapshot l·ªõn h∆°n, t·ªën ti·ªÅn h∆°n

```
C√°ch 1: T·∫•t c·∫£ trong root volume (50GB)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OS Ubuntu (10GB)            ‚îÇ  ‚Üê Kh√¥ng c·∫ßn backup
‚îÇ Nginx, MySQL binaries (5GB) ‚îÇ  ‚Üê Kh√¥ng c·∫ßn backup  
‚îÇ App data (35GB)             ‚îÇ  ‚Üê C·∫¶N backup
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Snapshot: 50GB ‚Üí tr·∫£ ti·ªÅn cho c·∫£ OS

C√°ch 2: T√°ch ri√™ng
Root (15GB): OS + apps        ‚Üí Kh√¥ng c·∫ßn snapshot th∆∞·ªùng xuy√™n
Data (35GB): Ch·ªâ data         ‚Üí Snapshot 35GB
‚Üí Ti·∫øt ki·ªám ~30% chi ph√≠ snapshot
```

#### 3. Restore ch·∫≠m h∆°n

```
C√°ch 1: Restore t·ª´ root snapshot
- Ph·∫£i launch EC2 m·ªõi ho·∫∑c t·∫°o AMI
- M·∫•t th·ªùi gian setup l·∫°i

C√°ch 2: T√°ch data volume
- Snapshot ‚Üí New Volume ‚Üí Attach ‚Üí Mount
- EC2 v·∫´n ch·∫°y, ch·ªâ swap volume
- Nhanh h∆°n nhi·ªÅu
```

#### 4. Kh√¥ng th·ªÉ attach v√†o instance kh√°c

```
Scenario: EC2 b·ªã l·ªói, c·∫ßn l·∫•y data g·∫•p

C√°ch 1 (root volume):
EC2 ch·∫øt ‚Üí Kh√¥ng SSH ƒë∆∞·ª£c ‚Üí Ph·∫£i t·∫°o snapshot ‚Üí ƒê·ª£i ‚Üí T·∫°o EC2 m·ªõi

C√°ch 2 (data volume):
EC2 ch·∫øt ‚Üí Detach data volume ‚Üí Attach v√†o EC2 kh√°c ‚Üí Mount ‚Üí L·∫•y data ngay
```

#### 5. Kh√¥ng th·ªÉ d√πng volume type kh√°c nhau

```
Root: gp3 (r·∫ª, ƒë·ªß cho OS)
Data: io2 (IOPS cao cho database)

N·∫øu g·ªôp chung ‚Üí ph·∫£i d√πng io2 cho c·∫£ OS (ƒë·∫Øt v√¥ √≠ch)
```

### Khi n√†o d√πng root volume cho t·∫•t c·∫£?

| Scenario | Ch·ªâ root volume | T√°ch data volume |
|----------|-----------------|------------------|
| Dev/test t·∫°m th·ªùi | ‚úÖ OK | Kh√¥ng c·∫ßn |
| Stateless app | ‚úÖ OK | Kh√¥ng c·∫ßn |
| Production database | ‚ùå R·ªßi ro | ‚úÖ N√™n t√°ch |
| Data quan tr·ªçng | ‚ùå R·ªßi ro | ‚úÖ N√™n t√°ch |

---

## EBS vs Instance Store

| ƒê·∫∑c ƒëi·ªÉm | EBS | Instance Store |
|----------|-----|----------------|
| Persistence | ‚úÖ Persistent (d·ªØ li·ªáu gi·ªØ l·∫°i sau stop/terminate) | ‚ùå Ephemeral (m·∫•t khi stop/terminate) |
| Detach/Attach | ‚úÖ C√≥ th·ªÉ | ‚ùå Kh√¥ng th·ªÉ |
| Backup | ‚úÖ Snapshots | ‚ùå Kh√¥ng c√≥ |
| Use case | Database, boot volumes | Cache, temporary data |

---

## C√°c lo·∫°i EBS Volume

### IOPS vs Throughput l√† g√¨?

Tr∆∞·ªõc khi xem c√°c lo·∫°i volume, c·∫ßn hi·ªÉu 2 kh√°i ni·ªám:

#### IOPS (Input/Output Operations Per Second)

**IOPS = s·ªë l·∫ßn ƒë·ªçc/ghi m·ªói gi√¢y**

```
Database MySQL:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SELECT * FROM users WHERE id = 1   ‚îÇ  ‚Üí 1 operation
‚îÇ SELECT * FROM users WHERE id = 2   ‚îÇ  ‚Üí 1 operation  
‚îÇ SELECT * FROM users WHERE id = 3   ‚îÇ  ‚Üí 1 operation
‚îÇ ...                                 ‚îÇ
‚îÇ 5000 queries/gi√¢y                   ‚îÇ  ‚Üí C·∫ßn 5000 IOPS
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**ƒê·∫∑c ƒëi·ªÉm:** Nhi·ªÅu thao t√°c nh·ªè, truy c·∫≠p ng·∫´u nhi√™n (random I/O)

#### Throughput (BƒÉng th√¥ng)

**Throughput = l∆∞·ª£ng data truy·ªÅn m·ªói gi√¢y (MB/s, MiB/s)**

```
Copy/Stream file l·ªõn:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Copy video 1GB                      ‚îÇ
‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 500 MiB/s  ‚îÇ  ‚Üí Throughput cao
‚îÇ Xong trong 2 gi√¢y                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**ƒê·∫∑c ƒëi·ªÉm:** √çt thao t√°c nh∆∞ng data l·ªõn, ƒë·ªçc tu·∫ßn t·ª± (sequential I/O)

#### So s√°nh IOPS vs Throughput

| | IOPS | Throughput |
|---|------|------------|
| **ƒêo g√¨** | S·ªë l·∫ßn ƒë·ªçc/ghi | L∆∞·ª£ng data/gi√¢y |
| **ƒê∆°n v·ªã** | operations/s | MiB/s |
| **Workload** | Database, random access | Video streaming, big data |
| **V√≠ d·ª•** | 10,000 queries nh·ªè/gi√¢y | Copy file 500MB/gi√¢y |

#### V√≠ d·ª• th·ª±c t·∫ø

```
Database MySQL (c·∫ßn IOPS cao):
- 5000 queries/gi√¢y, m·ªói query ƒë·ªçc 4KB
- IOPS c·∫ßn: 5000
- Throughput: 5000 √ó 4KB = 20 MB/s (th·∫•p)
‚Üí Ch·ªçn: gp3 ho·∫∑c io2

Video streaming/Big data (c·∫ßn Throughput cao):
- ƒê·ªçc file video li√™n t·ª•c
- IOPS: th·∫•p (√≠t operations)
- Throughput: 500 MB/s (cao)
‚Üí Ch·ªçn: st1
```

### SSD-backed Volumes (cho IOPS workloads)

| Type | Volume Type | Use Cases | Size | Max IOPS | Max Throughput |
|------|-------------|-----------|------|----------|----------------|
| **gp3** | General Purpose SSD | Boot volumes, dev/test, low-latency apps | 1 GiB - 64 TiB | 80,000 | 2,000 MiB/s |
| **gp2** | General Purpose SSD | Boot volumes, virtual desktops | 1 GiB - 16 TiB | 16,000 | 250 MiB/s |
| **io2 Block Express** | Provisioned IOPS SSD | Critical databases, sub-millisecond latency | 4 GiB - 64 TiB | 256,000 | 4,000 MiB/s |
| **io1** | Provisioned IOPS SSD | I/O-intensive databases | 4 GiB - 16 TiB | 64,000 | 1,000 MiB/s |

### HDD-backed Volumes (cho throughput workloads)

| Type | Volume Type | Use Cases | Size | Max IOPS | Max Throughput |
|------|-------------|-----------|------|----------|----------------|
| **st1** | Throughput Optimized HDD | Big data, data warehouses, log processing | 125 GiB - 16 TiB | 500 | 500 MiB/s |
| **sc1** | Cold HDD | Infrequent access, lowest cost | 125 GiB - 16 TiB | 250 | 250 MiB/s |

### L∆∞u √Ω quan tr·ªçng

- **Boot volume**: Ch·ªâ SSD volumes (gp2, gp3, io1, io2) ƒë∆∞·ª£c d√πng l√†m boot volume
- **gp3 vs gp2**: gp3 m·ªõi h∆°n, cho ph√©p configure IOPS v√† throughput ƒë·ªôc l·∫≠p
- **io2 Block Express**: Durability 99.999% (0.001% annual failure rate)
- C√°c lo·∫°i kh√°c: Durability 99.8%-99.9% (0.1%-0.2% annual failure rate)

> üìñ **Ngu·ªìn:** [Amazon EBS volume types](https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html)

---

## EBS Snapshots

**Snapshot** l√† b·∫£n backup point-in-time c·ªßa EBS volume, ƒë∆∞·ª£c l∆∞u tr·ªØ tr√™n **Amazon S3**.

```
EBS Volume (100GB)          Snapshot
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ /data            ‚îÇ  ‚îÄ‚îÄ‚ñ∫  ‚îÇ Backup l√∫c 10:00 ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ app/         ‚îÇ       ‚îÇ L∆∞u tr√™n S3      ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ db/          ‚îÇ       ‚îÇ Durability:      ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ logs/        ‚îÇ       ‚îÇ 99.999999999%    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Incremental Snapshots (ch·ªâ backup ph·∫ßn thay ƒë·ªïi)

```
Ng√†y 1: Volume c√≥ 100GB data
        Snapshot A: backup 100GB (full)

Ng√†y 2: Th√™m 5GB data m·ªõi
        Snapshot B: ch·ªâ backup 5GB (incremental)
        
Ng√†y 3: S·ª≠a 2GB data
        Snapshot C: ch·ªâ backup 2GB (incremental)

T·ªïng l∆∞u tr·ªØ: 100 + 5 + 2 = 107GB (kh√¥ng ph·∫£i 300GB)
```

**L·ª£i √≠ch:** Ti·∫øt ki·ªám storage cost, t·∫°o snapshot nhanh h∆°n.

### Snapshot vs Volume

| | EBS Volume | EBS Snapshot |
|---|------------|--------------|
| **L∆∞u ·ªü ƒë√¢u** | Trong 1 AZ | S3 (across AZs) |
| **Truy c·∫≠p** | Attach v√†o EC2 | Kh√¥ng truy c·∫≠p tr·ª±c ti·∫øp |
| **D√πng ƒë·ªÉ** | ƒê·ªçc/ghi data | Backup, restore, copy |
| **Gi·ªõi h·∫°n AZ** | B·ªã lock trong 1 AZ | C√≥ th·ªÉ copy cross-region |

### Use Cases

**1. Backup tr∆∞·ªõc khi l√†m g√¨ ƒë√≥ nguy hi·ªÉm:**
```
Tr∆∞·ªõc khi upgrade MySQL:
Volume ‚Üí Snapshot ‚Üí Upgrade ‚Üí L·ªói? ‚Üí Restore t·ª´ Snapshot
```

**2. Migrate data sang AZ/Region kh√°c:**
```
Volume (ap-southeast-1a) ‚Üí Snapshot ‚Üí Copy ‚Üí Snapshot (us-east-1) ‚Üí New Volume
```

**3. Share data v·ªõi account kh√°c:**
```
Snapshot (Account A) ‚Üí Share ‚Üí Account B c√≥ th·ªÉ t·∫°o Volume
```

### C√°c l·ªánh v·ªõi Snapshot

```bash
# T·∫°o snapshot
aws ec2 create-snapshot \
    --volume-id vol-0abc123 \
    --description "Backup before upgrade"

# T·∫°o volume t·ª´ snapshot
aws ec2 create-volume \
    --snapshot-id snap-0xyz789 \
    --availability-zone ap-southeast-1a \
    --volume-type gp3

# Copy snapshot sang region kh√°c
aws ec2 copy-snapshot \
    --source-region ap-southeast-1 \
    --source-snapshot-id snap-0xyz789 \
    --destination-region us-east-1

# X√≥a snapshot
aws ec2 delete-snapshot --snapshot-id snap-0xyz789
```

### Snapshot Lifecycle

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Volume    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ create-snapshot
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Snapshot (S3)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ Snap A  ‚îÇ‚îÄ‚îÄ‚îÇ Snap B  ‚îÇ‚îÄ‚îÄ‚îÇ Snap C  ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ (full)  ‚îÇ  ‚îÇ(increm.)‚îÇ  ‚îÇ(increm.)‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                           ‚îÇ
        ‚îÇ create-volume             ‚îÇ copy-snapshot
        ‚ñº                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ New Volume   ‚îÇ            ‚îÇ Snapshot in  ‚îÇ
‚îÇ (any AZ)     ‚îÇ            ‚îÇ other Region ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### L∆∞u √Ω quan tr·ªçng

| ƒêi·ªÅu c·∫ßn bi·∫øt | Chi ti·∫øt |
|---------------|----------|
| **Snapshot ƒëang t·∫°o** | Volume v·∫´n d√πng ƒë∆∞·ª£c b√¨nh th∆∞·ªùng |
| **Consistency** | N√™n stop I/O ho·∫∑c unmount tr∆∞·ªõc khi snapshot (ƒë·∫∑c bi·ªát v·ªõi DB) |
| **X√≥a snapshot gi·ªØa** | Kh√¥ng m·∫•t data, AWS t·ª± merge |
| **Encrypted volume** | Snapshot c≈©ng encrypted |
| **Lazy loading** | Volume t·ª´ snapshot c√≥ th·ªÉ ch·∫≠m l√∫c ƒë·∫ßu (data load t·ª´ S3) |

### EBS Snapshot Archive

- Tier l∆∞u tr·ªØ gi√° r·∫ª h∆°n 75%
- Y√™u c·∫ßu l∆∞u t·ªëi thi·ªÉu 90 ng√†y
- Th·ªùi gian restore: 24-72 gi·ªù
- D√πng cho: compliance, long-term backup

### Fast Snapshot Restore (FSR)

Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ lazy loading:

```
Kh√¥ng c√≥ FSR:
Volume m·ªõi ‚Üê lazy load t·ª´ S3 ‚Üê Snapshot
L·∫ßn ƒë·ªçc ƒë·∫ßu: ch·∫≠m

C√≥ FSR:
Volume m·ªõi ‚Üê data s·∫µn s√†ng ngay
L·∫ßn ƒë·ªçc ƒë·∫ßu: nhanh
```

**Chi ph√≠:** ~$0.75/snapshot/AZ/gi·ªù (ƒë·∫Øt, ch·ªâ d√πng khi c·∫ßn performance ngay)

---

## EBS Encryption

Amazon EBS encryption s·ª≠ d·ª•ng **AWS KMS** keys ƒë·ªÉ m√£ h√≥a:

- Data at rest trong volume
- Data in transit gi·ªØa volume v√† instance
- T·∫•t c·∫£ snapshots ƒë∆∞·ª£c t·∫°o t·ª´ volume
- T·∫•t c·∫£ volumes ƒë∆∞·ª£c t·∫°o t·ª´ encrypted snapshots

### L∆∞u √Ω:
- Encryption x·∫£y ra tr√™n EC2 host servers (transparent v·ªõi instance)
- Minimal impact on latency
- C√≥ th·ªÉ enable encryption by default cho t·∫•t c·∫£ new volumes trong account

---

## EBS Multi-Attach

Cho ph√©p attach m·ªôt **io1/io2** volume v√†o nhi·ªÅu EC2 instances c√πng l√∫c (trong c√πng AZ).

```
B√¨nh th∆∞·ªùng:                    Multi-Attach:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ EC2  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ EBS  ‚îÇ          ‚îÇEC2 A ‚îÇ‚îÄ‚îÄ‚îÄ‚îê
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ EBS  ‚îÇ
1:1                            ‚îÇEC2 B ‚îÇ‚îÄ‚îÄ‚îÄ‚î§     ‚îÇ(io2) ‚îÇ
                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
                               ‚îÇEC2 C ‚îÇ‚îÄ‚îÄ‚îÄ‚îò     1:N (max 16)
                               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### T·∫°i sao c·∫ßn Multi-Attach?

**V·∫•n ƒë·ªÅ: Failover ch·∫≠m khi kh√¥ng c√≥ Multi-Attach**

```
EC2 A (Active) ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ EBS Volume
EC2 B (Standby)     (kh√¥ng c√≥ data)

EC2 A ch·∫øt:
1. Detach volume t·ª´ EC2 A (ƒë·ª£i...)
2. Attach volume v√†o EC2 B (ƒë·ª£i...)
3. Mount trong EC2 B (ƒë·ª£i...)
‚Üí Downtime: 2-5 ph√∫t!
```

**Gi·∫£i ph√°p: Multi-Attach**

```
EC2 A (Active)  ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îú‚îÄ‚îÄ‚îÄ‚ñ∂ EBS Volume (c·∫£ 2 ƒë√£ attach s·∫µn)
EC2 B (Standby) ‚îÄ‚îÄ‚îÄ‚îò

EC2 A ch·∫øt ‚Üí EC2 B l√™n ngay!
‚Üí Downtime: v√†i gi√¢y
```

### V√≠ d·ª•: Oracle RAC (Database Cluster)

**Oracle RAC = nhi·ªÅu servers ch·∫°y c√πng 1 database**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Oracle RAC  ‚îÇ  ‚îÇ  Oracle RAC  ‚îÇ  ‚îÇ  Oracle RAC  ‚îÇ
‚îÇ   Node 1     ‚îÇ  ‚îÇ   Node 2     ‚îÇ  ‚îÇ   Node 3     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                 ‚îÇ                 ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ     EBS io2 Volume          ‚îÇ
         ‚îÇ     Multi-Attach Enabled    ‚îÇ
         ‚îÇ     (Shared Database)       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**T·∫°i sao RAC c·∫ßn shared storage?**

```
N·∫øu m·ªói node c√≥ EBS ri√™ng:
Node 1 ‚Üí EBS A: balance = 50  (ƒë√£ update)
Node 2 ‚Üí EBS B: balance = 100 (ch∆∞a update)
‚Üí Data kh√¥ng ƒë·ªìng b·ªô!

V·ªõi Multi-Attach (shared storage):
Node 1 ‚îÄ‚îÄ‚îÄ‚îê
          ‚îú‚îÄ‚îÄ‚ñ∂ Shared EBS: balance = 50
Node 2 ‚îÄ‚îÄ‚îÄ‚îò
‚Üí T·∫•t c·∫£ nodes th·∫•y c√πng 1 data
```

### C√°c Database kh√°c c√≥ c·∫ßn Multi-Attach kh√¥ng?

**KH√îNG!** ƒêa s·ªë database d√πng **Replication**, kh√¥ng c·∫ßn shared storage.

```
MySQL/PostgreSQL (Replication):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Primary ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ EBS A ‚îÇ ‚Üê Ghi v√†o ƒë√¢y
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ replicate (copy qua network)
     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Replica ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ EBS B ‚îÇ ‚Üê Data ƒë∆∞·ª£c copy sang
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚Üí M·ªói node c√≥ EBS RI√äNG, KH√îNG c·∫ßn Multi-Attach
```

### So s√°nh c√°c Database

| Database | C√°ch Clustering | C·∫ßn Multi-Attach? |
|----------|-----------------|-------------------|
| **Oracle RAC** | Shared Storage | ‚úÖ C·∫ßn |
| **SQL Server FCI** | Shared Storage | ‚úÖ C·∫ßn |
| **MySQL** | Replication | ‚ùå Kh√¥ng |
| **PostgreSQL** | Replication | ‚ùå Kh√¥ng |
| **MongoDB** | Replica Set | ‚ùå Kh√¥ng |
| **Redis** | Replication | ‚ùå Kh√¥ng |

### So s√°nh Shared Storage vs Replication

| | Shared Storage (Oracle RAC) | Replication (MySQL, PostgreSQL) |
|---|----------------------------|--------------------------------|
| **Write** | V√†o b·∫•t k·ª≥ node | Ch·ªâ v√†o Primary |
| **Data** | 1 b·∫£n, shared | Nhi·ªÅu b·∫£n, copy |
| **ƒê·ªô tr·ªÖ** | Kh√¥ng c√≥ | C√≥ (1-2 gi√¢y) |
| **C·∫ßn Multi-Attach** | ‚úÖ C√≥ | ‚ùå Kh√¥ng |
| **Ph·ªï bi·∫øn** | Enterprise (ng√¢n h√†ng) | ƒêa s·ªë ·ª©ng d·ª•ng |

### Gi·ªõi h·∫°n Multi-Attach

| Gi·ªõi h·∫°n | Chi ti·∫øt |
|----------|----------|
| **Volume type** | Ch·ªâ **io1** v√† **io2** |
| **S·ªë instances** | T·ªëi ƒëa **16** |
| **AZ** | T·∫•t c·∫£ instances ph·∫£i **c√πng AZ** |
| **OS** | Ch·ªâ **Linux** |
| **File system** | C·∫ßn **cluster-aware FS** (GFS2, OCFS2) |

### C√°ch b·∫≠t Multi-Attach

```bash
# T·∫°o volume v·ªõi Multi-Attach
aws ec2 create-volume \
    --availability-zone ap-southeast-1a \
    --volume-type io2 \
    --size 100 \
    --iops 10000 \
    --multi-attach-enabled

# Attach v√†o nhi·ªÅu instances
aws ec2 attach-volume --volume-id vol-xxx --instance-id i-111
aws ec2 attach-volume --volume-id vol-xxx --instance-id i-222
```

### Khi n√†o d√πng Multi-Attach?

| Scenario | D√πng Multi-Attach? |
|----------|-------------------|
| Oracle RAC, SQL Server FCI | ‚úÖ C·∫ßn |
| MySQL, PostgreSQL cluster | ‚ùå D√πng Replication |
| AWS managed (RDS, Aurora) | ‚ùå AWS lo h·∫øt |
| Web app th√¥ng th∆∞·ªùng | ‚ùå Kh√¥ng c·∫ßn |

### ‚ö†Ô∏è Nh·ªØng ƒëi·ªÅu c·∫ßn AWARE khi d√πng Multi-Attach

#### 1. Data Corruption n·∫øu kh√¥ng d√πng ƒë√∫ng File System

```
NGUY HI·ªÇM:
EC2 A: echo "hello" > /data/file.txt  ‚îÄ‚îÄ‚îê
                                        ‚îú‚îÄ‚îÄ‚ñ∂ file.txt b·ªã CORRUPT!
EC2 B: echo "world" > /data/file.txt  ‚îÄ‚îÄ‚îò

Hai instances ghi c√πng l√∫c v√†o 1 file = DATA CORRUPTION
```

**Gi·∫£i ph√°p:** PH·∫¢I d√πng **Cluster-aware File System**:

| File System | H·ªó tr·ª£ Multi-Attach |
|-------------|---------------------|
| ext4, xfs | ‚ùå KH√îNG - s·∫Ω corrupt data |
| GFS2 (Red Hat) | ‚úÖ C√≥ |
| OCFS2 (Oracle) | ‚úÖ C√≥ |

#### 2. Application ph·∫£i h·ªó tr·ª£ Shared Storage

```
‚ùå SAI: Ch·∫°y 2 MySQL instances tr√™n c√πng 1 Multi-Attach volume
       ‚Üí MySQL kh√¥ng thi·∫øt k·∫ø cho shared storage ‚Üí CORRUPT

‚úÖ ƒê√öNG: Oracle RAC ƒë∆∞·ª£c thi·∫øt k·∫ø cho shared storage
         ‚Üí C√≥ c∆° ch·∫ø locking, coordination gi·ªØa c√°c nodes
```

**Kh√¥ng ph·∫£i app n√†o c≈©ng d√πng ƒë∆∞·ª£c Multi-Attach!**

#### 3. I/O Fencing (tr√°nh Split-Brain)

```
V·∫•n ƒë·ªÅ Split-Brain:
Node 1 nghƒ© Node 2 ch·∫øt ‚Üí ti·∫øp t·ª•c ghi
Node 2 nghƒ© Node 1 ch·∫øt ‚Üí ti·∫øp t·ª•c ghi
‚Üí C·∫£ 2 ghi c√πng l√∫c ‚Üí DATA CORRUPTION

Gi·∫£i ph√°p: I/O Fencing
- Khi ph√°t hi·ªán node l·ªói ‚Üí "fence" (c√¥ l·∫≠p) node ƒë√≥
- Node b·ªã fence kh√¥ng th·ªÉ ghi v√†o volume n·ªØa
- C·∫ßn c·∫•u h√¨nh ƒë√∫ng trong cluster software
```

#### 4. T·∫•t c·∫£ instances ph·∫£i c√πng AZ

```
‚ùå KH√îNG ho·∫°t ƒë·ªông:
EC2 (ap-southeast-1a) ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îú‚îÄ‚îÄ‚ñ∂ EBS Volume (ap-southeast-1a)
EC2 (ap-southeast-1b) ‚îÄ‚îÄ‚îÄ‚îò  ‚Üê KH√îNG th·ªÉ attach!

‚úÖ Ho·∫°t ƒë·ªông:
EC2 (ap-southeast-1a) ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îú‚îÄ‚îÄ‚ñ∂ EBS Volume (ap-southeast-1a)
EC2 (ap-southeast-1a) ‚îÄ‚îÄ‚îÄ‚îò
```

‚Üí N·∫øu c·∫ßn cross-AZ ‚Üí d√πng EFS thay v√¨ EBS Multi-Attach

#### 5. Chi ph√≠ cao

```
Multi-Attach ch·ªâ v·ªõi io1/io2:
- io2: $0.125/GB + $0.065/IOPS
- 1TB + 10,000 IOPS = $125 + $650 = $775/th√°ng

So v·ªõi gp3:
- gp3: $0.08/GB + $0.005/IOPS (sau 3000 free)
- 1TB + 10,000 IOPS = $80 + $35 = $115/th√°ng

‚Üí Multi-Attach ƒë·∫Øt h∆°n ~6-7 l·∫ßn!
```

#### 6. Kh√¥ng t·ª± ƒë·ªông sync application state

```
Multi-Attach ch·ªâ share STORAGE, kh√¥ng share:
- Memory/RAM
- Process state
- Network connections
- Application cache

‚Üí Application ph·∫£i t·ª± handle coordination gi·ªØa c√°c nodes
```

### Checklist tr∆∞·ªõc khi d√πng Multi-Attach

| Ki·ªÉm tra | ƒê√£ l√†m? |
|----------|---------|
| App h·ªó tr·ª£ shared storage (Oracle RAC, SQL Server FCI)? | ‚òê |
| D√πng cluster-aware file system (GFS2, OCFS2)? | ‚òê |
| T·∫•t c·∫£ instances c√πng AZ? | ‚òê |
| ƒê√£ c·∫•u h√¨nh I/O fencing? | ‚òê |
| D√πng Nitro-based instances? | ‚òê |
| Ch·∫•p nh·∫≠n chi ph√≠ io1/io2? | ‚òê |
| ƒê√£ test failover scenario? | ‚òê |

> ‚ö†Ô∏è **Khuy·∫øn ngh·ªã:** N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, h√£y d√πng **EFS** ho·∫∑c **Replication** thay v√¨ Multi-Attach. Multi-Attach ph·ª©c t·∫°p v√† d·ªÖ g√¢y data corruption n·∫øu config sai.

---

## Elastic Volumes

Cho ph√©p thay ƒë·ªïi volume configuration **m√† kh√¥ng c·∫ßn downtime**:

- TƒÉng size
- Thay ƒë·ªïi volume type (v√≠ d·ª•: gp2 ‚Üí gp3)
- ƒêi·ªÅu ch·ªânh IOPS v√† throughput (v·ªõi gp3, io1, io2)

```bash
# V√≠ d·ª•: Modify volume size
aws ec2 modify-volume --volume-id vol-xxx --size 200

# Sau khi modify, c·∫ßn extend file system trong OS
```

---

## S·ª≠ d·ª•ng EBS Volume: Attach, Format, Mount

### V√≤ng ƒë·ªùi c·ªßa EBS Volume

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  T·∫°o m·ªõi    ‚îÇ ‚Üí  ‚îÇ   Attach    ‚îÇ ‚Üí  ‚îÇ   Format    ‚îÇ ‚Üí  ‚îÇ    Mount    ‚îÇ
‚îÇ  (Available)‚îÇ    ‚îÇ (In-use)    ‚îÇ    ‚îÇ (c√≥ FS)     ‚îÇ    ‚îÇ (d√πng ƒë∆∞·ª£c) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Tr·∫°ng th√°i 1: M·ªõi t·∫°o, ch∆∞a Attach

```
AWS Console:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Volume: vol-0abc123                ‚îÇ
‚îÇ  State: available                   ‚îÇ  ‚Üê ƒêang "tr√¥i n·ªïi", ch∆∞a g·∫Øn v√†o ƒë√¢u
‚îÇ  Size: 100 GiB                      ‚îÇ
‚îÇ  Attached to: -                     ‚îÇ  ‚Üê Kh√¥ng c√≥ instance
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

EC2 Instance:
$ lsblk
xvda    8G   ‚Üê Ch·ªâ th·∫•y root volume
              (kh√¥ng th·∫•y volume 100GB)
```

**·ªû tr·∫°ng th√°i n√†y:**
- Volume t·ªìn t·∫°i trong AWS, b·∫°n ƒëang tr·∫£ ti·ªÅn
- Nh∆∞ng ch∆∞a d√πng ƒë∆∞·ª£c v√¨ ch∆∞a g·∫Øn v√†o EC2 n√†o
- Gi·ªëng nh∆∞ mua ·ªï c·ª©ng nh∆∞ng ch∆∞a c·∫Øm v√†o m√°y t√≠nh

---

### Tr·∫°ng th√°i 2: ƒê√£ Attach, ch∆∞a Format

```
AWS Console:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Volume: vol-0abc123                ‚îÇ
‚îÇ  State: in-use                      ‚îÇ  ‚Üê ƒê√£ g·∫Øn v√†o instance
‚îÇ  Attached to: i-xyz789 (/dev/xvdb)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

EC2 Instance:
$ lsblk
xvda    8G   ‚Üê Root volume
xvdb  100G   ‚Üê Volume m·ªõi xu·∫•t hi·ªán!

$ sudo file -s /dev/xvdb
/dev/xvdb: data   ‚Üê "data" nghƒ©a l√† ch∆∞a c√≥ filesystem
```

**·ªû tr·∫°ng th√°i n√†y:**
- EC2 th·∫•y ·ªï c·ª©ng (`/dev/xvdb`)
- Nh∆∞ng **ch∆∞a l∆∞u file ƒë∆∞·ª£c** v√¨ ch∆∞a c√≥ filesystem
- Th·ª≠ mount s·∫Ω **b·ªã l·ªói**:

```bash
$ sudo mount /dev/xvdb /data
mount: /data: wrong fs type, bad option, bad superblock...
```

**C·∫ßn l√†m:** Format ƒë·ªÉ t·∫°o filesystem

```bash
$ sudo mkfs.ext4 /dev/xvdb
mke2fs 1.45.5 (07-Jan-2020)
Creating filesystem with 26214400 4k blocks...
Allocating group tables: done
Writing superblocks: done
```

---

### Tr·∫°ng th√°i 3: ƒê√£ Format, ch∆∞a Mount

```
$ sudo file -s /dev/xvdb
/dev/xvdb: Linux rev 1.0 ext4 filesystem data   ‚Üê ƒê√£ c√≥ filesystem!

$ lsblk
xvda    8G   /        ‚Üê Root ƒë√£ mount
xvdb  100G            ‚Üê C√≥ ·ªï nh∆∞ng ch∆∞a mount (kh√¥ng c√≥ mount point)
```

**·ªû tr·∫°ng th√°i n√†y:**
- ·ªî c·ª©ng ƒë√£ s·∫µn s√†ng l∆∞u file
- Nh∆∞ng **ch∆∞a truy c·∫≠p ƒë∆∞·ª£c** v√¨ ch∆∞a c√≥ "c·ª≠a v√†o"
- Kh√¥ng c√≥ th∆∞ m·ª•c n√†o tr·ªè ƒë·∫øn ·ªï n√†y

```bash
$ cd /dev/xvdb
-bash: cd: /dev/xvdb: Not a directory   ‚Üê Kh√¥ng v√†o ƒë∆∞·ª£c nh∆∞ th∆∞ m·ª•c
```

**C·∫ßn l√†m:** Mount v√†o m·ªôt th∆∞ m·ª•c

```bash
$ sudo mkdir /data
$ sudo mount /dev/xvdb /data
```

---

### Tr·∫°ng th√°i 4: ƒê√£ Mount (s·ª≠ d·ª•ng ƒë∆∞·ª£c)

```
$ lsblk
xvda    8G   /        ‚Üê Root volume
xvdb  100G  /data     ‚Üê ƒê√£ mount!

$ df -h
/dev/xvda    8G   2G   6G  25%  /
/dev/xvdb  100G   0G 100G   0%  /data   ‚Üê Th·∫•y ·ªï 100GB
```

**·ªû tr·∫°ng th√°i n√†y:**
- Truy c·∫≠p `/data` = truy c·∫≠p ·ªï 100GB
- M·ªçi file trong `/data` n·∫±m tr√™n EBS volume

```bash
$ cd /data
$ echo "hello" > test.txt    # L∆∞u v√†o EBS volume
$ ls -la
-rw-r--r-- 1 root root 6 Jan 24 10:00 test.txt
```

---

### T·ªïng h·ª£p c√°c tr·∫°ng th√°i

| Tr·∫°ng th√°i | EC2 th·∫•y kh√¥ng? | L∆∞u file ƒë∆∞·ª£c? | C·∫ßn l√†m g√¨? |
|------------|-----------------|----------------|-------------|
| **T·∫°o m·ªõi, ch∆∞a attach** | ‚ùå Kh√¥ng | ‚ùå Kh√¥ng | Attach v√†o EC2 |
| **Attached, ch∆∞a format** | ‚úÖ Th·∫•y `/dev/xvdb` | ‚ùå Kh√¥ng | Format (`mkfs.ext4`) |
| **Formatted, ch∆∞a mount** | ‚úÖ Th·∫•y `/dev/xvdb` | ‚ùå Kh√¥ng | Mount v√†o th∆∞ m·ª•c |
| **Mounted** | ‚úÖ Th·∫•y `/dev/xvdb` | ‚úÖ ƒê∆∞·ª£c | D√πng th√¥i! |

---

### L·ªánh ƒë·∫ßy ƒë·ªß t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi

```bash
# 1. Sau khi attach t·ª´ AWS Console, ki·ªÉm tra
lsblk
# xvda    8G
# xvdb  100G   ‚Üê volume m·ªõi

# 2. Ki·ªÉm tra ƒë√£ c√≥ filesystem ch∆∞a
sudo file -s /dev/xvdb
# N·∫øu output l√† "data" ‚Üí ch∆∞a format
# N·∫øu output c√≥ "ext4 filesystem" ‚Üí ƒë√£ format, skip b∆∞·ªõc 3

# 3. Format (CH·ªà v·ªõi volume tr·ªëng!)
sudo mkfs.ext4 /dev/xvdb

# 4. T·∫°o mount point
sudo mkdir /data

# 5. Mount
sudo mount /dev/xvdb /data

# 6. Ki·ªÉm tra
df -h | grep xvdb
# /dev/xvdb  100G   0G 100G   0%  /data

# 7. (Optional) Auto-mount khi reboot
echo '/dev/xvdb /data ext4 defaults,nofail 0 2' | sudo tee -a /etc/fstab
```

---

### L∆∞u √Ω quan tr·ªçng

| Tr∆∞·ªùng h·ª£p | C·∫ßn Format? |
|------------|-------------|
| Volume **m·ªõi t·∫°o** (tr·ªëng) | ‚úÖ C·∫ßn |
| Volume t·ª´ **Snapshot** | ‚ùå Kh√¥ng (ƒë√£ c√≥ filesystem + data) |
| **Root volume** | ‚ùå Kh√¥ng (AMI ƒë√£ format s·∫µn) |
| **Detach r·ªìi attach l·∫°i** | ‚ùå Kh√¥ng (filesystem v·∫´n c√≤n) |

> ‚ö†Ô∏è **C·∫¢NH B√ÅO:** Format volume ƒë√£ c√≥ data ‚Üí **M·∫§T H·∫æT DATA**!

---

## Data Lifecycle Manager (DLM)

Automate vi·ªác t·∫°o, retention, v√† deletion c·ªßa EBS snapshots:

- T·∫°o backup policies d·ª±a tr√™n schedule
- Cross-region copy
- Retention rules (gi·ªØ X snapshots g·∫ßn nh·∫•t)

---

## EBS Pricing (Chi ph√≠)

### C√°ch t√≠nh ph√≠ EBS

EBS t√≠nh ph√≠ theo **3 th√†nh ph·∫ßn ch√≠nh**:

```
T·ªïng chi ph√≠ = Storage + IOPS (n·∫øu c√≥) + Throughput (n·∫øu c√≥) + Snapshots
```

### 1. Storage (dung l∆∞·ª£ng)

T√≠nh theo **GB-month** (s·ªë GB √ó s·ªë th√°ng s·ª≠ d·ª•ng).

| Volume Type | Gi√° tham kh·∫£o (us-east-1) | Ghi ch√∫ |
|-------------|---------------------------|---------|
| **gp3** | ~$0.08/GB-month | R·∫ª nh·∫•t cho SSD |
| **gp2** | ~$0.10/GB-month | ƒê·∫Øt h∆°n gp3 |
| **io2** | ~$0.125/GB-month | + ph√≠ IOPS |
| **io1** | ~$0.125/GB-month | + ph√≠ IOPS |
| **st1** | ~$0.045/GB-month | HDD, throughput |
| **sc1** | ~$0.015/GB-month | HDD, r·∫ª nh·∫•t |

### 2. IOPS (ch·ªâ v·ªõi io1, io2, gp3)

| Volume Type | Ph√≠ IOPS |
|-------------|----------|
| **gp3** | 3,000 IOPS mi·ªÖn ph√≠, th√™m ~$0.005/IOPS-month |
| **io1/io2** | ~$0.065/IOPS-month |

### 3. Throughput (ch·ªâ v·ªõi gp3)

- **gp3**: 125 MiB/s mi·ªÖn ph√≠, th√™m ~$0.04/MiB/s-month

### 4. Snapshots

| Lo·∫°i | Gi√° |
|------|-----|
| Standard | ~$0.05/GB-month |
| Archive | ~$0.0125/GB-month (r·∫ª h∆°n 75%) |

### V√≠ d·ª• t√≠nh chi ph√≠

**Scenario: Web server v·ªõi database**

```
Root volume:  gp3, 20 GB
Data volume:  gp3, 100 GB, 5000 IOPS, 200 MiB/s
Snapshots:    50 GB

Chi ph√≠/th√°ng:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Root:     20 GB √ó $0.08           = $1.60           ‚îÇ
‚îÇ Data:     100 GB √ó $0.08          = $8.00           ‚îÇ
‚îÇ IOPS:     (5000-3000) √ó $0.005    = $10.00          ‚îÇ
‚îÇ Throughput: (200-125) √ó $0.04     = $3.00           ‚îÇ
‚îÇ Snapshots: 50 GB √ó $0.05          = $2.50           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ T·ªîNG:                             ‚âà $25.10/th√°ng    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### L∆∞u √Ω quan tr·ªçng v·ªÅ chi ph√≠

| ƒêi·ªÅu c·∫ßn bi·∫øt | Chi ti·∫øt |
|---------------|----------|
| **Tr·∫£ ti·ªÅn khi ch∆∞a d√πng** | Volume ·ªü tr·∫°ng th√°i `available` (ch∆∞a attach) v·∫´n t√≠nh ph√≠ |
| **Stop EC2 v·∫´n tr·∫£ ti·ªÅn EBS** | EC2 stop = kh√¥ng t√≠nh ph√≠ EC2, nh∆∞ng EBS v·∫´n t√≠nh |
| **Snapshot incremental** | Snapshot th·ª© 2 tr·ªü ƒëi ch·ªâ t√≠nh ph·∫ßn thay ƒë·ªïi |
| **Delete volume** | X√≥a volume m·ªõi h·∫øt ph√≠, ch·ªâ stop EC2 th√¨ kh√¥ng ƒë·ªß |

### So s√°nh chi ph√≠ c√°c volume type

```
Chi ph√≠ cho 100GB/th√°ng (ch·ªâ storage):

sc1:  $1.50   ‚ñà‚ñà‚ñà‚ñà
st1:  $4.50   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
gp3:  $8.00   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
gp2:  $10.00  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
io2:  $12.50  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (+ IOPS ph√≠)
```

### Tips ti·∫øt ki·ªám chi ph√≠

1. **D√πng gp3 thay gp2** - R·∫ª h∆°n 20% v√† performance t·ªët h∆°n
2. **X√≥a volume kh√¥ng d√πng** - Ki·ªÉm tra volumes ·ªü tr·∫°ng th√°i `available`
3. **X√≥a snapshots c≈©** - D√πng DLM ƒë·ªÉ t·ª± ƒë·ªông x√≥a
4. **D√πng sc1/st1** cho data √≠t truy c·∫≠p
5. **Archive snapshots** c·∫ßn gi·ªØ l√¢u (>90 ng√†y)

> üìñ **Gi√° ch√≠nh x√°c:** [Amazon EBS Pricing](https://aws.amazon.com/ebs/pricing/) (gi√° thay ƒë·ªïi theo region v√† th·ªùi ƒëi·ªÉm)

---

## Best Practices

1. **Ch·ªçn ƒë√∫ng volume type** theo workload:
   - Boot volumes: gp3 (cost-effective)
   - Databases: io2 Block Express (high IOPS, durability)
   - Big data: st1 (throughput)

2. **Enable encryption** cho sensitive data

3. **Regular snapshots** v·ªõi DLM policies

4. **Monitor v·ªõi CloudWatch**: VolumeReadOps, VolumeWriteOps, BurstBalance

5. **S·ª≠ d·ª•ng EBS-optimized instances** ƒë·ªÉ ƒë·∫°t full performance

---

## Li√™n k·∫øt

- [EC2](ec2.md) - EBS volumes ƒë∆∞·ª£c attach v√†o EC2 instances
- [VPC](vpc.md) - EBS volumes n·∫±m trong m·ªôt AZ c·ªßa VPC

---

## Tham kh·∫£o

- [Amazon EBS User Guide](https://docs.aws.amazon.com/ebs/latest/userguide/what-is-ebs.html)
- [EBS Volume Types](https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html)
- [Amazon EBS Pricing](https://aws.amazon.com/ebs/pricing/)
